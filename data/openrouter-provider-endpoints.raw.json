{
  "generatedAt": "2026-02-19T22:58:33.169Z",
  "source": "openrouter-provider-endpoints",
  "settings": {
    "providers": [
      "mistral",
      "nebius"
    ],
    "concurrency": 1,
    "retries": 2,
    "timeoutMs": 20000,
    "dryRun": false,
    "limit": null
  },
  "summary": {
    "catalogModelCount": 338,
    "scannedModelCount": 338,
    "successfulEndpointRequests": 338,
    "failedEndpointRequests": 0,
    "extractedEndpointRows": 52
  },
  "errors": [],
  "rows": [
    {
      "modelId": "minimax/minimax-m2.1",
      "providerName": "Nebius",
      "endpointName": "Nebius | minimax/minimax-m2.1",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 196608,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 3e-7,
      "completionCostPerToken": 0.0000012,
      "promptCostPer1M": 0.3,
      "completionCostPer1M": 1.2,
      "supportsImplicitCaching": false,
      "uptimeLast30m": null,
      "sourceModelPricingPrompt": 2.7e-7,
      "sourceModelPricingCompletion": 9.5e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "z-ai/glm-4.7",
      "providerName": "Nebius",
      "endpointName": "Nebius | z-ai/glm-4.7-20251222",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 202752,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 4e-7,
      "completionCostPerToken": 0.000002,
      "promptCostPer1M": 0.4,
      "completionCostPer1M": 2,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 99.43502824858757,
      "sourceModelPricingPrompt": 3.8e-7,
      "sourceModelPricingCompletion": 0.0000017,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/mistral-small-creative",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/mistral-small-creative-20251216",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 32768,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1e-7,
      "completionCostPerToken": 3e-7,
      "promptCostPer1M": 0.1,
      "completionCostPer1M": 0.3,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 1e-7,
      "sourceModelPricingCompletion": 3e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/devstral-2512",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/devstral-2512",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 262144,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 4e-7,
      "completionCostPerToken": 0.000002,
      "promptCostPer1M": 0.4,
      "completionCostPer1M": 2,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 4e-7,
      "sourceModelPricingCompletion": 0.000002,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/ministral-14b-2512",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/ministral-14b-2512",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 262144,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 2e-7,
      "completionCostPerToken": 2e-7,
      "promptCostPer1M": 0.2,
      "completionCostPer1M": 0.2,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 2e-7,
      "sourceModelPricingCompletion": 2e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/ministral-8b-2512",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/ministral-8b-2512",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 262144,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1.5e-7,
      "completionCostPerToken": 1.5e-7,
      "promptCostPer1M": 0.15,
      "completionCostPer1M": 0.15,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 1.5e-7,
      "sourceModelPricingCompletion": 1.5e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/ministral-3b-2512",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/ministral-3b-2512",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1e-7,
      "completionCostPerToken": 1e-7,
      "promptCostPer1M": 0.1,
      "completionCostPer1M": 0.1,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 1e-7,
      "sourceModelPricingCompletion": 1e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/mistral-large-2512",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/mistral-large-2512",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 262144,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 5e-7,
      "completionCostPerToken": 0.0000015,
      "promptCostPer1M": 0.5,
      "completionCostPer1M": 1.5,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 5e-7,
      "sourceModelPricingCompletion": 0.0000015,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "prime-intellect/intellect-3",
      "providerName": "Nebius",
      "endpointName": "Nebius | prime-intellect/intellect-3-20251126",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 131072,
      "maxCompletionTokens": 131072,
      "maxPromptTokens": null,
      "promptCostPerToken": 2e-7,
      "completionCostPerToken": 0.0000011,
      "promptCostPer1M": 0.2,
      "completionCostPer1M": 1.1,
      "supportsImplicitCaching": false,
      "uptimeLast30m": null,
      "sourceModelPricingPrompt": 2e-7,
      "sourceModelPricingCompletion": 0.0000011,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "moonshotai/kimi-k2-thinking",
      "providerName": "Nebius",
      "endpointName": "Nebius | moonshotai/kimi-k2-thinking-20251106",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 262144,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 6e-7,
      "completionCostPerToken": 0.0000025,
      "promptCostPer1M": 0.6,
      "completionCostPer1M": 2.5,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 4.7e-7,
      "sourceModelPricingCompletion": 0.000002,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/voxtral-small-24b-2507",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/voxtral-small-24b-2507",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 32000,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1e-7,
      "completionCostPerToken": 3e-7,
      "promptCostPer1M": 0.1,
      "completionCostPer1M": 0.3,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 1e-7,
      "sourceModelPricingCompletion": 3e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "nvidia/nemotron-nano-12b-v2-vl",
      "providerName": "Nebius",
      "endpointName": "Nebius | nvidia/nemotron-nano-12b-v2-vl",
      "tag": "nebius/bf16",
      "status": 0,
      "quantization": "bf16",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 7e-8,
      "completionCostPerToken": 2e-7,
      "promptCostPer1M": 0.07,
      "completionCostPer1M": 0.2,
      "supportsImplicitCaching": false,
      "uptimeLast30m": null,
      "sourceModelPricingPrompt": 7e-8,
      "sourceModelPricingCompletion": 2e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "qwen/qwen3-next-80b-a3b-thinking",
      "providerName": "Nebius",
      "endpointName": "Nebius | qwen/qwen3-next-80b-a3b-thinking-2509",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 128000,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1.5e-7,
      "completionCostPerToken": 0.0000012,
      "promptCostPer1M": 0.15,
      "completionCostPer1M": 1.2,
      "supportsImplicitCaching": false,
      "uptimeLast30m": null,
      "sourceModelPricingPrompt": 1.5e-7,
      "sourceModelPricingCompletion": 0.0000012,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "qwen/qwen3-30b-a3b-thinking-2507",
      "providerName": "Nebius",
      "endpointName": "Nebius | qwen/qwen3-30b-a3b-thinking-2507",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 262144,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1e-7,
      "completionCostPerToken": 3e-7,
      "promptCostPer1M": 0.1,
      "completionCostPer1M": 0.3,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 5.1e-8,
      "sourceModelPricingCompletion": 3.4e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "nousresearch/hermes-4-70b",
      "providerName": "Nebius",
      "endpointName": "Nebius | nousresearch/hermes-4-70b",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1.3e-7,
      "completionCostPerToken": 4e-7,
      "promptCostPer1M": 0.13,
      "completionCostPer1M": 0.4,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 1.3e-7,
      "sourceModelPricingCompletion": 4e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "nousresearch/hermes-4-405b",
      "providerName": "Nebius",
      "endpointName": "Nebius | nousresearch/hermes-4-405b",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 0.000001,
      "completionCostPerToken": 0.000003,
      "promptCostPer1M": 1,
      "completionCostPer1M": 3,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 0.000001,
      "sourceModelPricingCompletion": 0.000003,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/mistral-medium-3.1",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/mistral-medium-3.1",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 4e-7,
      "completionCostPerToken": 0.000002,
      "promptCostPer1M": 0.4,
      "completionCostPer1M": 2,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 4e-7,
      "sourceModelPricingCompletion": 0.000002,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "openai/gpt-oss-120b",
      "providerName": "Nebius",
      "endpointName": "Nebius | openai/gpt-oss-120b",
      "tag": "nebius/fp4",
      "status": 0,
      "quantization": "fp4",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1.5e-7,
      "completionCostPerToken": 6e-7,
      "promptCostPer1M": 0.15,
      "completionCostPer1M": 0.6,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 3.9e-8,
      "sourceModelPricingCompletion": 1.9e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "openai/gpt-oss-20b",
      "providerName": "Nebius",
      "endpointName": "Nebius | openai/gpt-oss-20b",
      "tag": "nebius/fp4",
      "status": 0,
      "quantization": "fp4",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 5e-8,
      "completionCostPerToken": 2e-7,
      "promptCostPer1M": 0.05,
      "completionCostPer1M": 0.2,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 3e-8,
      "sourceModelPricingCompletion": 1.4e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/codestral-2508",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/codestral-2508",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 256000,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 3e-7,
      "completionCostPerToken": 9e-7,
      "promptCostPer1M": 0.3,
      "completionCostPer1M": 0.9,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 3e-7,
      "sourceModelPricingCompletion": 9e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "qwen/qwen3-coder-30b-a3b-instruct",
      "providerName": "Nebius",
      "endpointName": "Nebius | qwen/qwen3-coder-30b-a3b-instruct",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 262144,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1e-7,
      "completionCostPerToken": 3e-7,
      "promptCostPer1M": 0.1,
      "completionCostPer1M": 0.3,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 7e-8,
      "sourceModelPricingCompletion": 2.7e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "qwen/qwen3-30b-a3b-instruct-2507",
      "providerName": "Nebius",
      "endpointName": "Nebius | qwen/qwen3-30b-a3b-instruct-2507",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 262144,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1e-7,
      "completionCostPerToken": 3e-7,
      "promptCostPer1M": 0.1,
      "completionCostPer1M": 0.3,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 9e-8,
      "sourceModelPricingCompletion": 3e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "z-ai/glm-4.5",
      "providerName": "Nebius",
      "endpointName": "Nebius | z-ai/glm-4.5",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 6e-7,
      "completionCostPerToken": 0.0000022,
      "promptCostPer1M": 0.6,
      "completionCostPer1M": 2.2,
      "supportsImplicitCaching": false,
      "uptimeLast30m": null,
      "sourceModelPricingPrompt": 5.5e-7,
      "sourceModelPricingCompletion": 0.000002,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "z-ai/glm-4.5-air",
      "providerName": "Nebius",
      "endpointName": "Nebius | z-ai/glm-4.5-air",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 2e-7,
      "completionCostPerToken": 0.0000012,
      "promptCostPer1M": 0.2,
      "completionCostPer1M": 1.2,
      "supportsImplicitCaching": false,
      "uptimeLast30m": null,
      "sourceModelPricingPrompt": 1.3e-7,
      "sourceModelPricingCompletion": 8.5e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "qwen/qwen3-coder",
      "providerName": "Nebius",
      "endpointName": "Nebius | qwen/qwen3-coder-480b-a35b-07-25",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 262144,
      "maxCompletionTokens": 262144,
      "maxPromptTokens": null,
      "promptCostPerToken": 4e-7,
      "completionCostPerToken": 0.0000018,
      "promptCostPer1M": 0.4,
      "completionCostPer1M": 1.8,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 2.2e-7,
      "sourceModelPricingCompletion": 0.000001,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "qwen/qwen3-235b-a22b-2507",
      "providerName": "Nebius",
      "endpointName": "Nebius | qwen/qwen3-235b-a22b-07-25",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 262144,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 2e-7,
      "completionCostPerToken": 6e-7,
      "promptCostPer1M": 0.2,
      "completionCostPer1M": 0.6,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 7.1e-8,
      "sourceModelPricingCompletion": 1e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "moonshotai/kimi-k2",
      "providerName": "Nebius",
      "endpointName": "Nebius | moonshotai/kimi-k2",
      "tag": "nebius/fp4",
      "status": 0,
      "quantization": "fp4",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 5e-7,
      "completionCostPerToken": 0.0000024,
      "promptCostPer1M": 0.5,
      "completionCostPer1M": 2.4,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 99.07063197026022,
      "sourceModelPricingPrompt": 5e-7,
      "sourceModelPricingCompletion": 0.0000024,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/devstral-medium",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/devstral-medium-2507",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 4e-7,
      "completionCostPerToken": 0.000002,
      "promptCostPer1M": 0.4,
      "completionCostPer1M": 2,
      "supportsImplicitCaching": false,
      "uptimeLast30m": null,
      "sourceModelPricingPrompt": 4e-7,
      "sourceModelPricingCompletion": 0.000002,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/devstral-small",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/devstral-small-2507",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1e-7,
      "completionCostPerToken": 3e-7,
      "promptCostPer1M": 0.1,
      "completionCostPer1M": 0.3,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 1e-7,
      "sourceModelPricingCompletion": 3e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/mistral-small-3.2-24b-instruct",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/mistral-small-3.2-24b-instruct-2506",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1e-7,
      "completionCostPerToken": 3e-7,
      "promptCostPer1M": 0.1,
      "completionCostPer1M": 0.3,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 6e-8,
      "sourceModelPricingCompletion": 1.8e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "deepseek/deepseek-r1-0528",
      "providerName": "Nebius",
      "endpointName": "Nebius | deepseek/deepseek-r1-0528",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 163840,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 8e-7,
      "completionCostPerToken": 0.0000024,
      "promptCostPer1M": 0.8,
      "completionCostPer1M": 2.4,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 4e-7,
      "sourceModelPricingCompletion": 0.00000175,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "deepseek/deepseek-r1-0528",
      "providerName": "Nebius",
      "endpointName": "Nebius | deepseek/deepseek-r1-0528",
      "tag": "nebius/fast",
      "status": 0,
      "quantization": "fp4",
      "contextLength": 32768,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 0.000002,
      "completionCostPerToken": 0.000006,
      "promptCostPer1M": 2,
      "completionCostPer1M": 6,
      "supportsImplicitCaching": false,
      "uptimeLast30m": null,
      "sourceModelPricingPrompt": 4e-7,
      "sourceModelPricingCompletion": 0.00000175,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/mistral-medium-3",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/mistral-medium-3",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 4e-7,
      "completionCostPerToken": 0.000002,
      "promptCostPer1M": 0.4,
      "completionCostPer1M": 2,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 4e-7,
      "sourceModelPricingCompletion": 0.000002,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "qwen/qwen3-32b",
      "providerName": "Nebius",
      "endpointName": "Nebius | qwen/qwen3-32b-04-28",
      "tag": "nebius/base",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 40960,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1e-7,
      "completionCostPerToken": 3e-7,
      "promptCostPer1M": 0.1,
      "completionCostPer1M": 0.3,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 99.99223210471123,
      "sourceModelPricingPrompt": 8e-8,
      "sourceModelPricingCompletion": 2.4e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "qwen/qwen2.5-coder-7b-instruct",
      "providerName": "Nebius",
      "endpointName": "Nebius | qwen/qwen2.5-coder-7b-instruct",
      "tag": "nebius/fast",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 32768,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 3e-8,
      "completionCostPerToken": 9e-8,
      "promptCostPer1M": 0.03,
      "completionCostPer1M": 0.09,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 3e-8,
      "sourceModelPricingCompletion": 9e-8,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
      "providerName": "Nebius",
      "endpointName": "Nebius | nvidia/llama-3.1-nemotron-ultra-253b-v1",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 6e-7,
      "completionCostPerToken": 0.0000018,
      "promptCostPer1M": 0.6,
      "completionCostPer1M": 1.8,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 6e-7,
      "sourceModelPricingCompletion": 0.0000018,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "deepseek/deepseek-chat-v3-0324",
      "providerName": "Nebius",
      "endpointName": "Nebius | deepseek/deepseek-chat-v3-0324",
      "tag": "nebius/fast",
      "status": 0,
      "quantization": "fp4",
      "contextLength": 32768,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 7.5e-7,
      "completionCostPerToken": 0.00000225,
      "promptCostPer1M": 0.75,
      "completionCostPer1M": 2.25,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 99.77678571428571,
      "sourceModelPricingPrompt": 1.9e-7,
      "sourceModelPricingCompletion": 8.7e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "google/gemma-3-27b-it",
      "providerName": "Nebius",
      "endpointName": "Nebius | google/gemma-3-27b-it",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 110000,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1e-7,
      "completionCostPerToken": 3e-7,
      "promptCostPer1M": 0.1,
      "completionCostPer1M": 0.3,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 4e-8,
      "sourceModelPricingCompletion": 1.5e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/mistral-saba",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/mistral-saba-2502",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 32768,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 2e-7,
      "completionCostPerToken": 6e-7,
      "promptCostPer1M": 0.2,
      "completionCostPer1M": 0.6,
      "supportsImplicitCaching": false,
      "uptimeLast30m": null,
      "sourceModelPricingPrompt": 2e-7,
      "sourceModelPricingCompletion": 6e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "meta-llama/llama-guard-3-8b",
      "providerName": "Nebius",
      "endpointName": "Nebius | meta-llama/llama-guard-3-8b",
      "tag": "nebius",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 2e-8,
      "completionCostPerToken": 6e-8,
      "promptCostPer1M": 0.02,
      "completionCostPer1M": 0.06,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 2e-8,
      "sourceModelPricingCompletion": 6e-8,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "qwen/qwen2.5-vl-72b-instruct",
      "providerName": "Nebius",
      "endpointName": "Nebius | qwen/qwen2.5-vl-72b-instruct",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 32000,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 2.5e-7,
      "completionCostPerToken": 7.5e-7,
      "promptCostPer1M": 0.25,
      "completionCostPer1M": 0.75,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 2.5e-7,
      "sourceModelPricingCompletion": 7.5e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "meta-llama/llama-3.3-70b-instruct",
      "providerName": "Nebius",
      "endpointName": "Nebius | meta-llama/llama-3.3-70b-instruct",
      "tag": "nebius/fp8",
      "status": -2,
      "quantization": "fp8",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1.3e-7,
      "completionCostPerToken": 4e-7,
      "promptCostPer1M": 0.13,
      "completionCostPer1M": 0.4,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 84.416,
      "sourceModelPricingPrompt": 1e-7,
      "sourceModelPricingCompletion": 3.2e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "meta-llama/llama-3.3-70b-instruct",
      "providerName": "Nebius",
      "endpointName": "Nebius | meta-llama/llama-3.3-70b-instruct",
      "tag": "nebius/fast",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 2.5e-7,
      "completionCostPerToken": 7.5e-7,
      "promptCostPer1M": 0.25,
      "completionCostPer1M": 0.75,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 1e-7,
      "sourceModelPricingCompletion": 3.2e-7,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/mistral-large-2411",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/mistral-large-2411",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 0.000002,
      "completionCostPerToken": 0.000006,
      "promptCostPer1M": 2,
      "completionCostPer1M": 6,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 0.000002,
      "sourceModelPricingCompletion": 0.000006,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/mistral-large-2407",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/mistral-large-2407",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 0.000002,
      "completionCostPerToken": 0.000006,
      "promptCostPer1M": 2,
      "completionCostPer1M": 6,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 0.000002,
      "sourceModelPricingCompletion": 0.000006,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/pixtral-large-2411",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/pixtral-large-2411",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 0.000002,
      "completionCostPerToken": 0.000006,
      "promptCostPer1M": 2,
      "completionCostPer1M": 6,
      "supportsImplicitCaching": false,
      "uptimeLast30m": null,
      "sourceModelPricingPrompt": 0.000002,
      "sourceModelPricingCompletion": 0.000006,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "meta-llama/llama-3.1-8b-instruct",
      "providerName": "Nebius",
      "endpointName": "Nebius | meta-llama/llama-3.1-8b-instruct",
      "tag": "nebius/fp8",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 2e-8,
      "completionCostPerToken": 6e-8,
      "promptCostPer1M": 0.02,
      "completionCostPer1M": 0.06,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 99.8731769181991,
      "sourceModelPricingPrompt": 2e-8,
      "sourceModelPricingCompletion": 5e-8,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "meta-llama/llama-3.1-8b-instruct",
      "providerName": "Nebius",
      "endpointName": "Nebius | meta-llama/llama-3.1-8b-instruct",
      "tag": "nebius/fast",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 3e-8,
      "completionCostPerToken": 9e-8,
      "promptCostPer1M": 0.03,
      "completionCostPer1M": 0.09,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 2e-8,
      "sourceModelPricingCompletion": 5e-8,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/mistral-nemo",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/mistral-nemo",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 131072,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 1.5e-7,
      "completionCostPerToken": 1.5e-7,
      "promptCostPer1M": 0.15,
      "completionCostPer1M": 0.15,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 2e-8,
      "sourceModelPricingCompletion": 4e-8,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "google/gemma-2-9b-it",
      "providerName": "Nebius",
      "endpointName": "Nebius | google/gemma-2-9b-it",
      "tag": "nebius/fast",
      "status": 0,
      "quantization": "fp8",
      "contextLength": 8192,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 3e-8,
      "completionCostPerToken": 9e-8,
      "promptCostPer1M": 0.03,
      "completionCostPer1M": 0.09,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 3e-8,
      "sourceModelPricingCompletion": 9e-8,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/mixtral-8x22b-instruct",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/mixtral-8x22b-instruct",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 65536,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 0.000002,
      "completionCostPerToken": 0.000006,
      "promptCostPer1M": 2,
      "completionCostPer1M": 6,
      "supportsImplicitCaching": false,
      "uptimeLast30m": null,
      "sourceModelPricingPrompt": 0.000002,
      "sourceModelPricingCompletion": 0.000006,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    },
    {
      "modelId": "mistralai/mistral-large",
      "providerName": "Mistral",
      "endpointName": "Mistral | mistralai/mistral-large",
      "tag": "mistral",
      "status": 0,
      "quantization": "unknown",
      "contextLength": 128000,
      "maxCompletionTokens": null,
      "maxPromptTokens": null,
      "promptCostPerToken": 0.000002,
      "completionCostPerToken": 0.000006,
      "promptCostPer1M": 2,
      "completionCostPer1M": 6,
      "supportsImplicitCaching": false,
      "uptimeLast30m": 100,
      "sourceModelPricingPrompt": 0.000002,
      "sourceModelPricingCompletion": 0.000006,
      "extractedAt": "2026-02-19T22:58:27.207Z"
    }
  ]
}